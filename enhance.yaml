
SOLVER:
  BASE_LR: 0.0002
  MAX_ITER: 2
  CHECKPOINT_PERIOD: 4
  MAX_KEEP: 16
  IMS_PER_BATCH: 2
  TEST_PER_BATCH: 1
  LAMBDA_GP: 10
  LAMBDA_PIXEL: 1000
#  """
#  1.the LAMBDA_SMOOTH should be small since a heavy smoothness penalty will result in flat 3D LUTs while limited transformation flexibility
#  2. the LAMBDA_MONOTONICITY , it can be relatively stronger, can help to update the parameters that may be not be activated by input data
#  3. the LAMBDA_SMOOTH more than 0.0001 leads to worse PSNR , but PSNR is insensitive to the choice LAMBDA_MONOTONICITY
#  4. base LAMBDA_SMOOTH and LAMBDA_MONOTONICITY (0.0001, 10)
#  """
  LAMBDA_SMOOTH: 1e-5  # 0 0.00001 0.0001 0.001 0.01 0.1
  LAMBDA_MONOTONICITY: 10.0 # 0.1 0 1.0 10 100 1000
  N_CRITIC: 1
  ADAM:
    B1: 0.9
    B2: 0.999

MODEL:
  WEIGHTS: "/mnt/data/train.output/adaptive.3dlut/image.lut.c18.1e-5/AdaptivePairedModel_final.pth"
  DEVICE: "cpu"
  ARCH: "AdaptivePairedModel"
  LUT:
    SUPPLEMENT_NUMS: 18
    DIMS: 64
  CLASSIFIER:
    PRETRAINED_PATH: ""
    ARCH: "ClassifierResnet"
    RESNET_ARCH: "resnet50"

DATALOADER:
  NUM_WORKERS: 1
  DATA_PATH: "/mnt/data/data.set/xintu.data/xt.image.enhancement.540"
  DATASET: "ImageDatasetXinTuTif"
  XT_TRAIN_INPUT_TXT: "no_aug.train_input.txt"
  XT_TRAIN_LABEL_TXT: "no_aug.train_label.txt"
  XT_TEST_TXT: "no_aug.test.txt"

OUTPUT_LOG_NAME: "imagelut"
OUTPUT_DIR: "/mnt/data/train.output/imagelut.test/c18"

# '7001_0429.tif'